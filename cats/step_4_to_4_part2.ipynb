{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering\n",
    "\n",
    "**Author(s):** bfoo@google.com, kozyr@google.com\n",
    "\n",
    "\n",
    "\n",
    "In this notebook, we gather exploratory data from our training set to do feature engineering and model tuning. Before running this notebook, make sure that:\n",
    "\n",
    "* You have already run steps 2 and 3 to collect and split your data into training, validation, and test. \n",
    "* Your entire training dataset is in a Cloud Storage Bucket such as gs://[your-bucket]/[dataprep-dir]/training_images/\n",
    "* You have a small subset of the training data available on your VM already (from the exploration we did in the previous notebook):\n",
    "\n",
    "\n",
    "```\n",
    "mkdir -p ~/data/training_small\n",
    "gsutil -m cp gs://$BUCKET/catimages/training_images/000*.png ~/data/training_small/\n",
    "gsutil -m cp gs://$BUCKET/catimages/training_images/001*.png ~/data/training_small/\n",
    "mkdir -p ~/data/debugging_small\n",
    "gsutil -m cp gs://$BUCKET/catimages/training_images/002*.png ~/data/debugging_small\n",
    "echo \"done!\"\n",
    "```\n",
    "\n",
    "Note that we only take the images starting with those IDs to limit the number we'll copy over to only a few thousand images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your username:\n",
    "YOUR_GMAIL_ACCOUNT = '******' # Whatever is before @gmail.com in your email address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries for this section:\n",
    "import os\n",
    "import cv2\n",
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directories:\n",
    "PREPROC_DIR = os.path.join('/home', YOUR_GMAIL_ACCOUNT, 'data/')\n",
    "TRAIN_DIR = os.path.join('/home', YOUR_GMAIL_ACCOUNT, 'data/training_small/')  # Where the training dataset lives.\n",
    "DEBUG_DIR = os.path.join('/home', YOUR_GMAIL_ACCOUNT, 'data/debugging_small/')  # Where the debugging dataset lives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering Functions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic features and concatenation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "def general_img_features(band):\n",
    "  \"\"\"\n",
    "  Define a set of features that we can look at for each color band\n",
    "  Args:\n",
    "    band: array which is one of blue, green, or red\n",
    "  Returns:\n",
    "    features: unique colors, nonzero count, mean, standard deviation,\n",
    "              min, and max of the channel's pixel values\n",
    "  \"\"\"\n",
    "  return [len(set(band.ravel())), np.count_nonzero(band),\n",
    "          np.mean(band), np.std(band),\n",
    "          band.min(), band.max()]\n",
    "\n",
    "def concat_all_band_features(file, dir):\n",
    "  \"\"\"\n",
    "  Extract features from a single image.\n",
    "   Args:\n",
    "         file - single image filename\n",
    "         dir - directory where the files are stored\n",
    "  Returns:\n",
    "         features - descriptive statistics for pixels\n",
    "  \"\"\"\n",
    "  img = cv2.imread(os.path.join(dir, file))\n",
    "  features = []\n",
    "  blue = np.float32(img[:,:,0])\n",
    "  green = np.float32(img[:,:,1])\n",
    "  red = np.float32(img[:,:,2])\n",
    "  features.extend(general_img_features(blue)) # indices 0-4\n",
    "  features.extend(general_img_features(green)) # indices 5-9\n",
    "  features.extend(general_img_features(red)) # indices 10-14\n",
    "  return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Harris Corner Detector Histograms\n",
    "\n",
    "We'll create features based on the histogram of the number of corners detected in every small square in the picture. The threshold indicates how \"sharp\" that corner must be to be detected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "def harris_density(harris_img, square_size, threshold):\n",
    "  \"\"\"Apply Harris Corner Detection to image and get count of corners.\n",
    "\n",
    "  Args:\n",
    "    harris_img: image already processed by Harris Corner Detector (in cv2 package).\n",
    "    square_size: number of pixels per side of the window in which we detect corners. \n",
    "    threshold: indicates how \"sharp\" that corner must be to be detected.\n",
    "\n",
    "  Returns:  \n",
    "    bins - counts in each bin of histogram.\n",
    "  \"\"\"\n",
    "  max_val = harris_img.max()\n",
    "  shape = harris_img.shape\n",
    "  bins = [0] * (square_size * square_size + 1)\n",
    "  for row in xrange(0, shape[0], square_size):\n",
    "      for col in xrange(0, shape[1], square_size):\n",
    "          bin_val = sum(sum(harris_img[row: row + square_size,\n",
    "                                       col: col + square_size] > threshold * max_val))\n",
    "          bins[int(bin_val)] += 1\n",
    "  return bins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Feature Vectors\n",
    "\n",
    "We've defined some functions and checked their outputs. Here is a sample feature vector constructor from pulling out summary features from grayscale, red, green, and blue channels along with harris corner detector output thresholding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(img_path):\n",
    "  \"\"\"Engineer the features and output feature vectors.\n",
    "  \n",
    "  Args:\n",
    "    img_path: filepath to image file\n",
    "    \n",
    "  Returns:\n",
    "    features: np array of features\n",
    "  \"\"\"\n",
    "  img = cv2.imread(img_path)\n",
    "  # Get the channels\n",
    "  gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "  blue = np.float32(img[:, :, 0])\n",
    "  green = np.float32(img[:, :, 1])\n",
    "  red = np.float32(img[:, :, 2])\n",
    "\n",
    "  # Run general summarization on each\n",
    "  features = general_img_features(gray)\n",
    "  features.extend(general_img_features(blue))\n",
    "  features.extend(general_img_features(green))\n",
    "  features.extend(general_img_features(red))\n",
    "\n",
    "  # Get Harris corner detection output\n",
    "  gray = cv2.cornerHarris(gray, 2, 3, 0.04)\n",
    "  blue = cv2.cornerHarris(blue, 2, 3, 0.04)\n",
    "  green = cv2.cornerHarris(green, 2, 3, 0.04)\n",
    "  red = cv2.cornerHarris(red, 2, 3, 0.04)\n",
    "\n",
    "  # Get general stats on each Harris detector results\n",
    "  features.extend(general_img_features(gray))\n",
    "  features.extend(general_img_features(blue))\n",
    "  features.extend(general_img_features(green))\n",
    "  features.extend(general_img_features(red))\n",
    "\n",
    "  # Get density bins on Harris detector results\n",
    "  features.extend(harris_density(gray, 4, 0.05))\n",
    "\n",
    "  return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features_and_labels(dir):\n",
    "  \"\"\"Get preprocessed features and labels.\n",
    "\n",
    "  Args:\n",
    "    dir: directory containing image files\n",
    "\n",
    "  Returns:\n",
    "    features: np array of features\n",
    "    labels: 1-d np array of binary labels\n",
    "  \"\"\"\n",
    "  i = 0\n",
    "  features = None\n",
    "  labels = []\n",
    "  print('\\nImages processed (out of {:d})...'.format(len(os.listdir(dir))))\n",
    "  for filename in os.listdir(dir):\n",
    "    feature_row = np.array([get_features(os.path.join(dir, filename))])\n",
    "    if features is not None:\n",
    "      features = np.append(features, feature_row, axis=0)\n",
    "    else:\n",
    "      features = feature_row\n",
    "    split_filename = filename.split('_')\n",
    "    label = int(split_filename[-1].split('.')[0])\n",
    "    labels = np.append(labels, label)\n",
    "    i += 1\n",
    "    if i % 100 == 0:\n",
    "      print(features.shape[0])\n",
    "  print(features.shape[0])\n",
    "  return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a limited set of images, this is computationally expensive:\n",
    "training_features, training_labels = get_features_and_labels(TRAIN_DIR)\n",
    "debugging_features, debugging_labels = get_features_and_labels(DEBUG_DIR)\n",
    "\n",
    "print('\\nDone!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standardize and save\n",
    "\n",
    "If we don't want the magnitude of a feature column to have an undue influence on the results, we should standardize our features. **Standardization** is a process where the mean is subtracted from feature values, and the result is divided by the standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize features:\n",
    "standardizer = preprocessing.StandardScaler().fit(training_features)\n",
    "training_std = standardizer.transform(training_features)\n",
    "debugging_std = standardizer.transform(debugging_features)\n",
    "\n",
    "# Save features as pkl:\n",
    "pickle.dump(training_std, open(os.path.join(PREPROC_DIR, 'training_std.pkl'), 'w'))\n",
    "pickle.dump(debugging_std, open(os.path.join(PREPROC_DIR, 'debugging_std.pkl'), 'w'))\n",
    "pickle.dump(training_labels, open(os.path.join(PREPROC_DIR, 'training_labels.pkl'), 'w'))\n",
    "pickle.dump(debugging_labels, open(os.path.join(PREPROC_DIR, 'debugging_labels.pkl'), 'w'))\n",
    "\n",
    "print ('\\nFeaturing engineering is complete!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
